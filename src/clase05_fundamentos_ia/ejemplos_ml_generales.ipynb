{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos Pr√°cticos de Machine Learning\n",
    "## Conceptos Fundamentales con C√≥digo Python\n",
    "\n",
    "Este notebook contiene ejemplos pr√°cticos de diferentes t√©cnicas de Machine Learning aplicadas a problemas reales diversos.\n",
    "\n",
    "### Contenido:\n",
    "1. Regresi√≥n Lineal - Predicci√≥n de precios de casas\n",
    "2. Clasificaci√≥n - Detecci√≥n de spam\n",
    "3. Clustering - Segmentaci√≥n de clientes\n",
    "4. Series Temporales - Predicci√≥n de demanda\n",
    "5. NLP - An√°lisis de sentimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as esenciales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. REGRESI√ìN LINEAL: Predicci√≥n de Precios de Casas\n",
    "\n",
    "**Objetivo**: Predecir el precio de una casa bas√°ndose en sus caracter√≠sticas\n",
    "\n",
    "**Tipo**: Regresi√≥n (valor continuo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generar datos sint√©ticos de casas\n",
    "print(\"üè† PREDICCI√ìN DE PRECIOS DE CASAS\\n\")\n",
    "\n",
    "# Crear dataset sint√©tico\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Features: tama√±o (m¬≤), habitaciones, antig√ºedad, distancia centro\n",
    "tamano = np.random.uniform(50, 300, n_samples)  # m¬≤\n",
    "habitaciones = np.random.randint(1, 6, n_samples)\n",
    "antiguedad = np.random.uniform(0, 50, n_samples)  # a√±os\n",
    "distancia_centro = np.random.uniform(0, 30, n_samples)  # km\n",
    "\n",
    "# Precio basado en f√≥rmula con ruido\n",
    "precio = (\n",
    "    2000 * tamano +  # ‚Ç¨2000 por m¬≤\n",
    "    15000 * habitaciones +  # ‚Ç¨15000 por habitaci√≥n\n",
    "    -500 * antiguedad +  # Depreciaci√≥n por a√±o\n",
    "    -1000 * distancia_centro +  # Menos valor lejos del centro\n",
    "    np.random.normal(0, 20000, n_samples)  # Ruido\n",
    ")\n",
    "\n",
    "# Crear DataFrame\n",
    "df_casas = pd.DataFrame({\n",
    "    'tamano_m2': tamano,\n",
    "    'habitaciones': habitaciones,\n",
    "    'antiguedad_anos': antiguedad,\n",
    "    'distancia_centro_km': distancia_centro,\n",
    "    'precio': precio\n",
    "})\n",
    "\n",
    "print(\"Dataset creado con\", len(df_casas), \"casas\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "display(df_casas.head(10))\n",
    "\n",
    "print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "display(df_casas.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n visual\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Scatter plots de cada feature vs precio\n",
    "features = ['tamano_m2', 'habitaciones', 'antiguedad_anos', 'distancia_centro_km']\n",
    "titles = ['Tama√±o vs Precio', 'Habitaciones vs Precio', 'Antig√ºedad vs Precio', 'Distancia vs Precio']\n",
    "\n",
    "for idx, (feature, title) in enumerate(zip(features, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.scatter(df_casas[feature], df_casas['precio'], alpha=0.5)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Precio (‚Ç¨)')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # L√≠nea de tendencia\n",
    "    z = np.polyfit(df_casas[feature], df_casas['precio'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(df_casas[feature], p(df_casas[feature]), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para el modelo\n",
    "X = df_casas[features]\n",
    "y = df_casas['precio']\n",
    "\n",
    "# Dividir en train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {len(X_train)} casas\")\n",
    "print(f\"Conjunto de prueba: {len(X_test)} casas\")\n",
    "\n",
    "# Entrenar modelo de regresi√≥n lineal\n",
    "modelo_precio = LinearRegression()\n",
    "modelo_precio.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Modelo entrenado\")\n",
    "print(\"\\nCoeficientes aprendidos:\")\n",
    "for feature, coef in zip(features, modelo_precio.coef_):\n",
    "    print(f\"  {feature:25s}: {coef:>10,.2f} ‚Ç¨\")\n",
    "print(f\"  {'Intercepto':25s}: {modelo_precio.intercept_:>10,.2f} ‚Ç¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "y_pred_train = modelo_precio.predict(X_train)\n",
    "y_pred_test = modelo_precio.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\"üìä M√âTRICAS DEL MODELO:\\n\")\n",
    "print(f\"R¬≤ (Train): {r2_train:.3f}\")\n",
    "print(f\"R¬≤ (Test):  {r2_test:.3f}\")\n",
    "print(f\"\\nRMSE (Train): ‚Ç¨{rmse_train:,.2f}\")\n",
    "print(f\"RMSE (Test):  ‚Ç¨{rmse_test:,.2f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "print(f\"  - El modelo explica el {r2_test*100:.1f}% de la varianza en los precios\")\n",
    "print(f\"  - Error promedio de predicci√≥n: ‚Ç¨{rmse_test:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de predicciones vs realidad\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot predicho vs real\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Predicci√≥n perfecta')\n",
    "ax1.set_xlabel('Precio Real (‚Ç¨)')\n",
    "ax1.set_ylabel('Precio Predicho (‚Ç¨)')\n",
    "ax1.set_title(f'Predicciones vs Realidad (R¬≤={r2_test:.3f})')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuci√≥n de errores\n",
    "ax2 = axes[1]\n",
    "errores = y_test - y_pred_test\n",
    "ax2.hist(errores, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Error = 0')\n",
    "ax2.set_xlabel('Error de Predicci√≥n (‚Ç¨)')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "ax2.set_title('Distribuci√≥n de Errores')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de predicci√≥n para una casa nueva\n",
    "print(\"üè° PREDICCI√ìN PARA CASA NUEVA:\\n\")\n",
    "\n",
    "casa_nueva = pd.DataFrame({\n",
    "    'tamano_m2': [120],\n",
    "    'habitaciones': [3],\n",
    "    'antiguedad_anos': [10],\n",
    "    'distancia_centro_km': [5]\n",
    "})\n",
    "\n",
    "precio_predicho = modelo_precio.predict(casa_nueva)[0]\n",
    "\n",
    "print(\"Caracter√≠sticas de la casa:\")\n",
    "print(f\"  - Tama√±o: {casa_nueva['tamano_m2'][0]} m¬≤\")\n",
    "print(f\"  - Habitaciones: {casa_nueva['habitaciones'][0]}\")\n",
    "print(f\"  - Antig√ºedad: {casa_nueva['antiguedad_anos'][0]} a√±os\")\n",
    "print(f\"  - Distancia al centro: {casa_nueva['distancia_centro_km'][0]} km\")\n",
    "print(f\"\\nüí∞ Precio predicho: ‚Ç¨{precio_predicho:,.2f}\")\n",
    "\n",
    "# Intervalo de confianza aproximado\n",
    "intervalo = 1.96 * rmse_test  # 95% confianza\n",
    "print(f\"\\nIntervalo de confianza (95%):\")\n",
    "print(f\"  Entre ‚Ç¨{precio_predicho - intervalo:,.2f} y ‚Ç¨{precio_predicho + intervalo:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. CLASIFICACI√ìN: Detecci√≥n de Spam en Emails\n",
    "\n",
    "**Objetivo**: Clasificar emails como spam o no-spam\n",
    "\n",
    "**Tipo**: Clasificaci√≥n binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"üìß DETECCI√ìN DE SPAM EN EMAILS\\n\")\n",
    "\n",
    "# Crear dataset sint√©tico de emails\n",
    "emails_spam = [\n",
    "    \"OFERTA INCRE√çBLE!!! Compra ahora y ahorra 90%\",\n",
    "    \"¬°¬°¬°GANA DINERO R√ÅPIDO!!! Haz clic aqu√≠\",\n",
    "    \"Enhorabuena has ganado un iPhone gratis\",\n",
    "    \"Oferta exclusiva solo para ti !!! URGENTE\",\n",
    "    \"Descuento del 99% en productos de lujo\",\n",
    "    \"Haz click aqu√≠ para ganar 1000 euros\",\n",
    "    \"VIAGRA barata compra ahora sin receta\",\n",
    "    \"Trabajo desde casa gana dinero f√°cil\",\n",
    "    \"Promoci√≥n limitada oferta incre√≠ble descuento\",\n",
    "    \"Premio loter√≠a has ganado millones\"\n",
    "] * 5  # Repetir para tener m√°s datos\n",
    "\n",
    "emails_legit = [\n",
    "    \"Reuni√≥n el lunes a las 10:00 en la sala de juntas\",\n",
    "    \"Hola, adjunto el informe que pediste\",\n",
    "    \"Confirmaci√≥n de tu pedido n√∫mero 12345\",\n",
    "    \"Gracias por tu compra, aqu√≠ est√° tu factura\",\n",
    "    \"Recordatorio: cita m√©dica ma√±ana a las 3pm\",\n",
    "    \"El proyecto est√° avanzando seg√∫n lo planeado\",\n",
    "    \"Feliz cumplea√±os, espero que pases un gran d√≠a\",\n",
    "    \"Te env√≠o las fotos de las vacaciones\",\n",
    "    \"Necesito que revises este documento por favor\",\n",
    "    \"La reuni√≥n de ma√±ana se ha cancelado\"\n",
    "] * 5\n",
    "\n",
    "# Crear DataFrame\n",
    "df_emails = pd.DataFrame({\n",
    "    'texto': emails_spam + emails_legit,\n",
    "    'es_spam': [1]*len(emails_spam) + [0]*len(emails_legit)\n",
    "})\n",
    "\n",
    "# Mezclar\n",
    "df_emails = df_emails.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset: {len(df_emails)} emails\")\n",
    "print(f\"  - Spam: {df_emails['es_spam'].sum()}\")\n",
    "print(f\"  - Leg√≠timo: {len(df_emails) - df_emails['es_spam'].sum()}\")\n",
    "print(\"\\nEjemplos:\")\n",
    "display(df_emails.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizaci√≥n de texto con TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X_emails = vectorizer.fit_transform(df_emails['texto'])\n",
    "y_emails = df_emails['es_spam']\n",
    "\n",
    "print(\"Vocabulario aprendido (primeras 20 palabras):\")\n",
    "print(vectorizer.get_feature_names_out()[:20])\n",
    "print(f\"\\nDimensionalidad: {X_emails.shape}\")\n",
    "print(f\"  - {X_emails.shape[0]} emails\")\n",
    "print(f\"  - {X_emails.shape[1]} features (palabras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en train/test\n",
    "X_train_email, X_test_email, y_train_email, y_test_email = train_test_split(\n",
    "    X_emails, y_emails, test_size=0.3, random_state=42, stratify=y_emails\n",
    ")\n",
    "\n",
    "# Entrenar clasificador Naive Bayes\n",
    "clf_spam = MultinomialNB()\n",
    "clf_spam.fit(X_train_email, y_train_email)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_email = clf_spam.predict(X_test_email)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "accuracy = accuracy_score(y_test_email, y_pred_email)\n",
    "\n",
    "print(\"‚úÖ Modelo entrenado\")\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "print(\"\\nReporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test_email, y_pred_email, \n",
    "                           target_names=['Leg√≠timo', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test_email, y_pred_email)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['Leg√≠timo', 'Spam'],\n",
    "           yticklabels=['Leg√≠timo', 'Spam'])\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.title('Matriz de Confusi√≥n - Detector de Spam')\n",
    "\n",
    "# A√±adir explicaci√≥n\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "plt.text(1.5, 2.5, f'VP={tp}\\nFP={fp}\\nFN={fn}\\nVN={tn}', \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "print(f\"  - Verdaderos Positivos (TP): {tp} - Spam correctamente detectado\")\n",
    "print(f\"  - Falsos Positivos (FP): {fp} - Leg√≠timo marcado como spam (¬°malo!)\")\n",
    "print(f\"  - Falsos Negativos (FN): {fn} - Spam no detectado (¬°malo!)\")\n",
    "print(f\"  - Verdaderos Negativos (TN): {tn} - Leg√≠timo correctamente identificado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con emails nuevos\n",
    "print(\"üß™ PRUEBAS CON EMAILS NUEVOS:\\n\")\n",
    "\n",
    "emails_prueba = [\n",
    "    \"Reuni√≥n ma√±ana para discutir el proyecto\",\n",
    "    \"¬°¬°¬°OFERTA LIMITADA!!! Gana dinero r√°pido\",\n",
    "    \"Confirmaci√≥n de tu reserva de hotel\",\n",
    "    \"COMPRA AHORA y ahorra 95% URGENTE\"\n",
    "]\n",
    "\n",
    "X_prueba = vectorizer.transform(emails_prueba)\n",
    "predicciones = clf_spam.predict(X_prueba)\n",
    "probabilidades = clf_spam.predict_proba(X_prueba)\n",
    "\n",
    "for email, pred, proba in zip(emails_prueba, predicciones, probabilidades):\n",
    "    label = \"üì© SPAM\" if pred == 1 else \"‚úÖ LEG√çTIMO\"\n",
    "    confianza = proba[pred] * 100\n",
    "    print(f\"{label} ({confianza:.1f}% confianza)\")\n",
    "    print(f\"  Email: '{email}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. CLUSTERING: Segmentaci√≥n de Clientes\n",
    "\n",
    "**Objetivo**: Agrupar clientes en segmentos similares sin etiquetas previas\n",
    "\n",
    "**Tipo**: Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"üë• SEGMENTACI√ìN DE CLIENTES\\n\")\n",
    "\n",
    "# Generar datos sint√©ticos de clientes\n",
    "np.random.seed(42)\n",
    "n_clientes = 300\n",
    "\n",
    "# Crear 3 grupos naturales de clientes\n",
    "# Grupo 1: J√≥venes, bajos ingresos, muchas compras peque√±as\n",
    "grupo1 = pd.DataFrame({\n",
    "    'edad': np.random.normal(25, 3, 100),\n",
    "    'ingreso_anual': np.random.normal(25000, 5000, 100),\n",
    "    'gasto_mensual': np.random.normal(200, 50, 100),\n",
    "    'frecuencia_compra': np.random.normal(15, 3, 100)\n",
    "})\n",
    "\n",
    "# Grupo 2: Adultos, ingresos medios, compras moderadas\n",
    "grupo2 = pd.DataFrame({\n",
    "    'edad': np.random.normal(40, 5, 100),\n",
    "    'ingreso_anual': np.random.normal(50000, 10000, 100),\n",
    "    'gasto_mensual': np.random.normal(500, 100, 100),\n",
    "    'frecuencia_compra': np.random.normal(8, 2, 100)\n",
    "})\n",
    "\n",
    "# Grupo 3: Seniors, altos ingresos, compras caras pero pocas\n",
    "grupo3 = pd.DataFrame({\n",
    "    'edad': np.random.normal(55, 7, 100),\n",
    "    'ingreso_anual': np.random.normal(80000, 15000, 100),\n",
    "    'gasto_mensual': np.random.normal(1000, 200, 100),\n",
    "    'frecuencia_compra': np.random.normal(4, 1, 100)\n",
    "})\n",
    "\n",
    "df_clientes = pd.concat([grupo1, grupo2, grupo3], ignore_index=True)\n",
    "\n",
    "print(f\"Dataset: {len(df_clientes)} clientes\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "display(df_clientes.head(10))\n",
    "\n",
    "print(\"\\nEstad√≠sticas:\")\n",
    "display(df_clientes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n inicial\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Edad vs Ingreso\n",
    "axes[0].scatter(df_clientes['edad'], df_clientes['ingreso_anual'], alpha=0.6)\n",
    "axes[0].set_xlabel('Edad')\n",
    "axes[0].set_ylabel('Ingreso Anual (‚Ç¨)')\n",
    "axes[0].set_title('Edad vs Ingreso')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Frecuencia vs Gasto\n",
    "axes[1].scatter(df_clientes['frecuencia_compra'], df_clientes['gasto_mensual'], alpha=0.6)\n",
    "axes[1].set_xlabel('Frecuencia de Compra (veces/mes)')\n",
    "axes[1].set_ylabel('Gasto Mensual (‚Ç¨)')\n",
    "axes[1].set_title('Frecuencia vs Gasto')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Se pueden observar posibles agrupaciones naturales en los datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar datos (importante para K-Means)\n",
    "scaler = StandardScaler()\n",
    "X_clientes_scaled = scaler.fit_transform(df_clientes)\n",
    "\n",
    "# M√©todo del codo para encontrar K √≥ptimo\n",
    "inertias = []\n",
    "K_range = range(1, 10)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_clientes_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Visualizar m√©todo del codo\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('N√∫mero de Clusters (K)')\n",
    "plt.ylabel('Inercia (Within-Cluster Sum of Squares)')\n",
    "plt.title('M√©todo del Codo para encontrar K √≥ptimo')\n",
    "plt.axvline(x=3, color='r', linestyle='--', label='K=3 (codo)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° El 'codo' sugiere que K=3 es √≥ptimo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means con K=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df_clientes['cluster'] = kmeans.fit_predict(X_clientes_scaled)\n",
    "\n",
    "print(\"‚úÖ Clustering completado\")\n",
    "print(f\"\\nDistribuci√≥n de clientes por cluster:\")\n",
    "print(df_clientes['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Analizar caracter√≠sticas de cada cluster\n",
    "print(\"\\nüìä PERFIL DE CADA CLUSTER:\\n\")\n",
    "cluster_profiles = df_clientes.groupby('cluster').mean()\n",
    "display(cluster_profiles.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "# Edad vs Ingreso coloreado por cluster\n",
    "for cluster in [0, 1, 2]:\n",
    "    mask = df_clientes['cluster'] == cluster\n",
    "    axes[0].scatter(df_clientes.loc[mask, 'edad'], \n",
    "                   df_clientes.loc[mask, 'ingreso_anual'],\n",
    "                   c=colors[cluster], label=f'Cluster {cluster}', alpha=0.6, s=50)\n",
    "axes[0].set_xlabel('Edad')\n",
    "axes[0].set_ylabel('Ingreso Anual (‚Ç¨)')\n",
    "axes[0].set_title('Clusters: Edad vs Ingreso')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Frecuencia vs Gasto coloreado por cluster\n",
    "for cluster in [0, 1, 2]:\n",
    "    mask = df_clientes['cluster'] == cluster\n",
    "    axes[1].scatter(df_clientes.loc[mask, 'frecuencia_compra'], \n",
    "                   df_clientes.loc[mask, 'gasto_mensual'],\n",
    "                   c=colors[cluster], label=f'Cluster {cluster}', alpha=0.6, s=50)\n",
    "axes[1].set_xlabel('Frecuencia de Compra (veces/mes)')\n",
    "axes[1].set_ylabel('Gasto Mensual (‚Ç¨)')\n",
    "axes[1].set_title('Clusters: Frecuencia vs Gasto')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretaci√≥n de clusters\n",
    "print(\"üéØ INTERPRETACI√ìN DE CLUSTERS:\\n\")\n",
    "\n",
    "for cluster in [0, 1, 2]:\n",
    "    perfil = cluster_profiles.loc[cluster]\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(f\"  - Edad promedio: {perfil['edad']:.0f} a√±os\")\n",
    "    print(f\"  - Ingreso anual: ‚Ç¨{perfil['ingreso_anual']:,.0f}\")\n",
    "    print(f\"  - Gasto mensual: ‚Ç¨{perfil['gasto_mensual']:,.0f}\")\n",
    "    print(f\"  - Frecuencia: {perfil['frecuencia_compra']:.1f} compras/mes\")\n",
    "    \n",
    "    # Etiqueta descriptiva\n",
    "    if perfil['edad'] < 30:\n",
    "        etiqueta = \"üéì J√≥venes Activos\"\n",
    "    elif perfil['edad'] < 50:\n",
    "        etiqueta = \"üëî Profesionales Establecidos\"\n",
    "    else:\n",
    "        etiqueta = \"üíé Premium Selectivos\"\n",
    "    \n",
    "    print(f\"  Etiqueta: {etiqueta}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusiones\n",
    "\n",
    "### Conceptos clave aprendidos:\n",
    "\n",
    "1. **Regresi√≥n Lineal**:\n",
    "   - Predice valores continuos\n",
    "   - Interpreta coeficientes como impacto de cada feature\n",
    "   - M√©tricas: R¬≤, RMSE, MAE\n",
    "\n",
    "2. **Clasificaci√≥n (Naive Bayes)**:\n",
    "   - Predice categor√≠as discretas\n",
    "   - Matriz de confusi√≥n para analizar errores\n",
    "   - Trade-off entre Precision y Recall\n",
    "\n",
    "3. **Clustering (K-Means)**:\n",
    "   - Encuentra grupos naturales sin etiquetas\n",
    "   - M√©todo del codo para elegir K\n",
    "   - Normalizaci√≥n crucial para distancias\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "\n",
    "- Experimentar con datasets reales (Kaggle, UCI)\n",
    "- Probar otros algoritmos (Random Forest, XGBoost, SVM)\n",
    "- Aprender t√©cnicas de feature engineering\n",
    "- Estudiar validaci√≥n cruzada y grid search\n",
    "- Explorar deep learning para problemas complejos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
